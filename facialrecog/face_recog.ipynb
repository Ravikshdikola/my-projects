{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## collecting samples from webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in c:\\users\\pc-lenovo\\anaconda\\envs\\tensorflow\\lib\\site-packages (20.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imgaug in c:\\users\\pc-lenovo\\anaconda\\envs\\tensorflow\\lib\\site-packages (0.4.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\pc-lenovo\\anaconda\\envs\\tensorflow\\lib\\site-packages (from imgaug) (7.1.2)\n",
      "Requirement already satisfied: imageio in c:\\users\\pc-lenovo\\anaconda\\envs\\tensorflow\\lib\\site-packages (from imgaug) (2.8.0)\n",
      "Requirement already satisfied: six in c:\\users\\pc-lenovo\\anaconda\\envs\\tensorflow\\lib\\site-packages (from imgaug) (1.14.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\pc-lenovo\\anaconda\\envs\\tensorflow\\lib\\site-packages (from imgaug) (1.4.1)\n",
      "Requirement already satisfied: Shapely in c:\\users\\pc-lenovo\\anaconda\\envs\\tensorflow\\lib\\site-packages (from imgaug) (1.7.0)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\pc-lenovo\\anaconda\\envs\\tensorflow\\lib\\site-packages (from imgaug) (1.18.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\pc-lenovo\\anaconda\\envs\\tensorflow\\lib\\site-packages (from imgaug) (3.1.3)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\pc-lenovo\\anaconda\\envs\\tensorflow\\lib\\site-packages (from imgaug) (4.2.0.34)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-image>=0.14.2 in c:\\users\\pc-lenovo\\anaconda\\envs\\tensorflow\\lib\\site-packages (from imgaug) (0.16.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\pc-lenovo\\anaconda\\envs\\tensorflow\\lib\\site-packages (from matplotlib->imgaug) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\pc-lenovo\\anaconda\\envs\\tensorflow\\lib\\site-packages (from matplotlib->imgaug) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\pc-lenovo\\anaconda\\envs\\tensorflow\\lib\\site-packages (from matplotlib->imgaug) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\pc-lenovo\\anaconda\\envs\\tensorflow\\lib\\site-packages (from matplotlib->imgaug) (1.2.0)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in c:\\users\\pc-lenovo\\anaconda\\envs\\tensorflow\\lib\\site-packages (from scikit-image>=0.14.2->imgaug) (1.1.1)\n",
      "Requirement already satisfied: networkx>=2.0 in c:\\users\\pc-lenovo\\anaconda\\envs\\tensorflow\\lib\\site-packages (from scikit-image>=0.14.2->imgaug) (2.4)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\pc-lenovo\\anaconda\\envs\\tensorflow\\lib\\site-packages (from networkx>=2.0->scikit-image>=0.14.2->imgaug) (4.4.2)\n"
     ]
    }
   ],
   "source": [
    "pip install imgaug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\pc-lenovo\\anaconda\\envs\\tensorflow\\lib\\site-packages (4.2.0.34)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\pc-lenovo\\anaconda\\envs\\tensorflow\\lib\\site-packages (from opencv-contrib-python) (1.18.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "collecting samples complete!!!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('C:/Users/PC-LENOVO/anaconda/Lib/site-packages/cv2/data/haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_extractor(img): # so the image we work under gray scale not in rgb\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray,1.3,6)\n",
    "     # 1.3 is scale factor\n",
    "     # 5 is minimum numbers of neighbours its value vary between 3 and 6 but the value at 6 or nearer to 6 give good result\n",
    "     \n",
    "    if faces is (): # if face is not present\n",
    "        return None\n",
    "    \n",
    "    for (x,y,w,h) in faces:  # for loop is for cropping frontal faces to see ity\n",
    "        cropped_face = img[y:y+h,x:x+w] # y is for rows and x is for columns\n",
    "    \n",
    "    return cropped_face\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "cap = cv2.VideoCapture(0) # 0 is our by default camera id\n",
    "count = 0  # this variable is derive to take the number of photos\n",
    "\n",
    "while True :\n",
    "    ret, frame = cap.read()\n",
    "     \n",
    "    if face_extractor(frame) is not None:\n",
    "         count+=1\n",
    "         face = cv2.resize(face_extractor(frame),(200,200)) # we resize the image to 200,200\n",
    "         face = cv2.cvtColor(face,cv2.COLOR_BGR2GRAY) # now convert that img to gray\n",
    "         file_name_path = 'C:/Users/PC-LENOVO/Downloads/facial tutorial/faces/user'+str(count)+'.jpg' # now we save the face value so for that we have to define a path to aparticular file # user we define in path is the name of the samples we collected and count should be depicted in string format in jpg\n",
    "         cv2.imwrite(file_name_path,face) # so it basically saving it for that we pass path and image\n",
    "         cv2.putText(face,str(count),(50,50),cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2) # 50,50 is size it detect 0,255,0 define green color rbg 1 defines the scale 2 defines the font size\n",
    "         cv2.imshow('Face Cropper',face) # it shows us current face samples\n",
    "    else:\n",
    "        print(\"Face not found\")\n",
    "        pass\n",
    "    \n",
    "    if cv2.waitKey(1)==13 or count==100:  #  now for closing it  13 is the asci code for enter to stop capturing photo or it will take 100 samples \n",
    "        break\n",
    "        \n",
    "        \n",
    "cap.release() # now we have to release the camera\n",
    "cv2.destroyAllWindows()\n",
    "print(\"collecting samples complete!!!\")\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training that model by using those samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Training is Completed\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir # this helps in fetching data from current working directory\n",
    "from os.path import isfile, join\n",
    "\n",
    "data_path = 'C:/Users/PC-LENOVO/Downloads/facial tutorial/faces/' # so we place / at the end of working directory to fetch the data\n",
    "onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path,f))] # so it basically join the corrent working directory to fetch the data stored in it\n",
    "\n",
    "Training_Data, Labels = [],[] # so we have two empty list to insert training data and labels\n",
    "\n",
    "for i,files in enumerate(onlyfiles): # enumerate provide the number of iteration according to the amount of data saved inside it\n",
    "    image_path = data_path + onlyfiles[i]\n",
    "    images = cv2.imread(image_path,cv2.IMREAD_GRAYSCALE) # so it defines images we are fetching is in gray scale\n",
    "    Training_Data.append(np.asarray(images,dtype=np.uint8)) # uint is unsigned integer\n",
    "    Labels.append(i)\n",
    "\n",
    "Labels = np.asarray(Labels, dtype=np.int32)\n",
    "\n",
    "model = cv2.face.LBPHFaceRecognizer_create() # LINEAR BINARY PHASE HISTROGRAM RECOGNIZER so our classification model is built up\n",
    "\n",
    "model.train(np.asarray(Training_Data),np.asarray(Labels))\n",
    "\n",
    "print(\"Model Training is Completed\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_classifier = cv2.CascadeClassifier('C:/Users/PC-LENOVO/anaconda/Lib/site-packages/cv2/data/haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_detector(img, size=0.5):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # so it convert img to grayscale\n",
    "    faces = face_classifier.detectMultiScale(gray,1.3,6)\n",
    "    \n",
    "    if faces is():# image is not present\n",
    "        return img,[]\n",
    "\n",
    "    for(x,y,w,h) in faces: # we scan each area of faces\n",
    "        cv2.rectangle(img, (x,y),(x+w,y+h),(0,255,0),2) # so it shows rectangle through x,y and x+w,y+h this shows how much increament should be done in the face and (0,255,0) shows the color of the rectangle 2 shows the thickness of the rectangle\n",
    "        roi = img[y:y+h,x:x+w]# region of interest\n",
    "        roi = cv2.resize(roi,(200,200))\n",
    "    \n",
    "    return img,roi\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    \n",
    "    ret,frame = cap.read()\n",
    "    \n",
    "    image, face = face_detector(frame)\n",
    "    \n",
    "    try:\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        result = model.predict(face)\n",
    "        \n",
    "        if result[1] < 500: # if the first value in result is lesser than 500\n",
    "            confidence = int(100*(1-(result[1])/300)) # we find the confidence value which describe how much percentage of faces will match\n",
    "            display_string = str(confidence)+'% Confidence it is user' # it prints the integer value\n",
    "           \n",
    "        cv2.putText(image,display_string,(100,120),cv2.FONT_HERSHEY_COMPLEX,1,(250,120,255),2)# (250,120,255) is a color (100,120) is size 1 is scale 2 is font\n",
    "        \n",
    "        if confidence >75:\n",
    "            cv2.putText(image,\"Unlocked\",(250,450),cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2) \n",
    "            cv2.imshow('Face Cropper', image)\n",
    "        \n",
    "        else:\n",
    "            cv2.putText(image,\"Locked\",(250,450),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),2) \n",
    "            cv2.imshow('Face Cropper', image)\n",
    "        \n",
    "    except:\n",
    "            cv2.putText(image,\"Face Not Found\",(250,450),cv2.FONT_HERSHEY_COMPLEX,1,(255,0,0),2) \n",
    "            cv2.imshow('Face Cropper', image)\n",
    "            pass # it heps in countinous running\n",
    "        \n",
    "        \n",
    "    if cv2.waitKey(1)==13:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
